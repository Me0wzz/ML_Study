# 선형회귀

$y = mx + b$

y: 예측하려는 변수
m: 선의 기울기
x: 입력 특성의 값
b: y 절편

$y' = b+ w_1x_1$

y': 예측된 라벨(원하는 출력)
b: 편향 (w_0)
w_1: 특성 1의 가중치
x_1: 특성(알려진 입력)

N 가지 특성을 사용하는 모델

$y' = b + w_1x_1 + w_2x_2 + ... + w_nx_n$

모델 학습: 모든 가중치와 편향의 양호한 값을 결정, 손실 최소화된 모델 시도함
이 프로세스를 경험적 위험 최소화

손실: 잘못된 예측의 페널티

예측 완벽하면 $손실 = 0$

그렇지 않으면 $손실 > 0$

## $L_2$ 손실 함수

$MSE$: 오차를 제곱한 평균

$MSE = \frac{1}{n}\sum\limits_{(x,y)\in D}(y-pred(x))^2$

$D$: 라벨이 있는 데이터 (x, y) 세트

$N$: D 데이터 갯수
